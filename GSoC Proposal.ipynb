{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-decoration:underline\">GSoC Project Proposal</h1>\n",
    "<h1 style=\"text-decoration:underline\">Add Variational Inference Interface to PyMC4</h1>\n",
    "\n",
    "## Description\n",
    "`Variational Inference` is a powerful algorithm that turns the task of computing the posterior(p(z|x)) into an optimization problem.  This project is about implementing two inference algorithms Mean Field ADVI and Full Rank ADVI based on [ADVI](https://arxiv.org/abs/1603.00788) paper in PyMC4. Mean Field ADVI posits a spherical Gaussian family and Full Rank ADVI posits a Multivariate Gaussian family to minimize KL divergence. The implementation will use tf and tfp libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base class for Approximation\n",
    "class Approximation:\n",
    "    \n",
    "    # Defining parameters\n",
    "    def __init__(self, model, size, random_seed=None):\n",
    "        self.model = model\n",
    "        self.size = size\n",
    "        self.random_seed = random_seed\n",
    "        # Handle initialization of mu and std\n",
    "        \n",
    "    @property\n",
    "    def mean(self):\n",
    "        return self.mu\n",
    "\n",
    "    @property\n",
    "    def std(self):\n",
    "        return self.std\n",
    "\n",
    "    # For Naive Monte Carlo\n",
    "    def random(self):\n",
    "        g = tf.random.Generator.from_seed(self.random_seed)\n",
    "        n = g.normal(shape=some_shape)\n",
    "        return self.std*n + self.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanField(Approximation):\n",
    "    \n",
    "    def __init__(self, model, size, random_seed):\n",
    "        super().__init__(model, size, random_seed)\n",
    "        \n",
    "    def cov(self):\n",
    "        sq = tf.math.square(self.std)\n",
    "        return tf.linalg.diag_part(sq)\n",
    "\n",
    "\n",
    "class FullRank(Approximation):\n",
    "    \n",
    "    def __init__(self, model, size, random_seed):\n",
    "        super().__init__(model, size, random_seed)\n",
    "    \n",
    "    def L(self):\n",
    "        n = self.size\n",
    "        entries = n*(n+1)//2\n",
    "        L = np.zeros([n, n], dtype=int)\n",
    "        L[np.tril_indices(n)] = np.arange(entries)\n",
    "        L[np.tril_indices(n)[::-1]] = np.arange(entries)\n",
    "        return L\n",
    "        \n",
    "    def cov(self):\n",
    "        L = self.L\n",
    "        return tf.linalg.matmul(L, tf.transpose(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, n=10000, random_seed=None, method='MeanFieldADVI'):\n",
    "    \n",
    "    # Transform the model into an unconstrained space\n",
    "    _, state = pm.evaluate_model_transformed(model)\n",
    "    logpt = state.collect_log_prob()\n",
    "        \n",
    "    # Collect the free random variables\n",
    "    untransformed = state.untransformed_values\n",
    "    free_RVs = untransformed.update(state.transformed_values)\n",
    "    \n",
    "    # Not sure about the use of local random variables\n",
    "    size = 0\n",
    "    for name, dist in free_RVs.items():\n",
    "        size += int(np.prod(dist.event_shape))\n",
    "    \n",
    "    approx = None\n",
    "    if method == \"MeanFieldADVI\":\n",
    "        approx = MeanField(model, size, random_seed)\n",
    "    else:\n",
    "        approx = FullRank(model, size, random_seed)\n",
    "\n",
    "    # Create variational gradient tensor\n",
    "    q = approx.random()\n",
    "    elbo = q + tf.reduce_sum(approx.std) + 0.5*size*(1 + tf.math.log(2.0*np.pi))\n",
    "    \n",
    "    # Set up optimizer\n",
    "    \n",
    "    # Draw samples from variational posterior\n",
    "\n",
    "    # TODO: Plot the trace using ArviZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Challenges\n",
    "\n",
    "1. **theano.clone equivalent for Tf2**: For drawing samples from posterior, we need to replace some nodes of the graph with variational distributions. PyMC3 achieves this by using `theano.clone`. Tensorflow v1 implements some similar functions in the `contrib` module - [tf.contrib.copy_graph](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib/copy_graph). But the tf.contrib has been deprecated in TF2. Support of symbolic graph manipulations has also been removed. \n",
    " - `tf.keras.backend` can be used for symbolic graphs. \n",
    " - `tf-nightly` provides [tf.raw_ops.Copy](https://www.tensorflow.org/api_docs/python/tf/raw_ops/Copy) for recursive deep copying of tensor. Maybe it is possible to implement a feature similar to `theano.clone` by looking upon implementations of both `copy_graph`(in tf.v1) and `Copy`(in tf.nightly).\n",
    "\n",
    "\n",
    "2. Provide an interface for flattened view of variables. PyMC3 does this using `theano.ravel()`. Maybe it can be accomplished by `tf.reshape`.\n",
    "\n",
    "3. Design an interface to account for minibatches. \n",
    "\n",
    "4. Figure out a way to optimize ELBO. `tf.keras.optimizers` is an option or provide an iterative optimization algorithm.\n",
    "\n",
    "5. Handle the initialization of means and stds for MeanField and Full Rank ADVI.\n",
    "\n",
    "6. Provide a reusable interface to implement more inference algorithms (SVGD, ASVGD).\n",
    "\n",
    "7. Progress Bar ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline\n",
    " - Pre GSoC Period: March 10 - March 20 <br/>\n",
    "Figure out the solutions of Challenges described above. I will make design less and less abstract as the time progresses and submit the proposal.\n",
    "\n",
    "\n",
    " - Student Application and Review Application Period: March 20 - April 27 <br />\n",
    "I will get myself more familiar with codebase of PyMC3, PyMC4 and begin implementing a few functions.\n",
    "\n",
    "\n",
    " - Community Bonding Period: April 27 - May 18 <br/> \n",
    "I will finalize implementation design for both algorithms by seeking reviews from mentors and community and also referring to OPVI and ADVI paper.\n",
    "\n",
    "\n",
    " - Week 1 - 2: May 18 - May 31 <br/>\n",
    "The actual coding begins. By this time, I will have a fair idea of interface design. I will begin implementing base Approximation class.\n",
    "\n",
    "\n",
    " - Week 3 - 4: June 1 - June 14 <br/>\n",
    "During this interval, I will implement utility functions (theano.clone and flatten). For every functionality, I will write test cases. Also I will create a progress report for phase 1 evaluations.\n",
    "\n",
    "\n",
    " - Evaluation Phase 1: June 15 - June 19 <br/>\n",
    "At this time, my focus will be on writing visual illustrations/notebooks for use cases of these base classes.\n",
    "\n",
    "\n",
    " - Week 5 - 6: June 20 - July 3 <br/>\n",
    "Having implemented base classes, I will write Mean Field Approximation class and pm.fit function to make inference. \n",
    "\n",
    "\n",
    " - Week 7: July 4 - July 12 <br/>\n",
    "I am not sure if I will be able to complete the implementation of Mean Field and fit function. I will also look for handling inference for mini batches. Designing progress reports.\n",
    "\n",
    "\n",
    " - Evaluation Phase 2: July 13 - July 17 <br/>\n",
    "Again, writing notebooks/blogs to explain good use cases.\n",
    "\n",
    "\n",
    " - Week 8 - 9: July 18 - July 31 <br />\n",
    "Implementation of FullRank Approximation class. Alter the pm.fit function to also account for Full Rank advi option.\n",
    "\n",
    "\n",
    " - Week 10: August 1 - August 9 <br />\n",
    "Account for mini batches in Full Rank ADVI. Tests in Pytest. Writing illustrations/blogs.\n",
    "\n",
    "\n",
    " - Final Submission of Code: August 10\n",
    "\n",
    "\n",
    " - Post GSoC Period: August 11 onwards <br/>\n",
    "I will learn and implement SVGD, ASVGD inference algorithms and become a permanent contributor to the organisation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributing to PyMC4\n",
    "1. Pull Request [#220](https://github.com/pymc-devs/pymc4/pull/220) (Merged): Add AutoRegressive distribution - <br/>\n",
    "This PR added Auto Regressive distribution by wrapping `sts.AutoRegressive` Model. The main task was to call `make_state_space_model` method with suitable arguments to capture the underlying the `tfd.LinearGaussianStateSpaceModel`. It took a lot of debugging to make this AR class compatible with PyMC4.\n",
    "\n",
    "2. Pull Request [#215](https://github.com/pymc-devs/pymc4/pull/215) (Merged): Add default transform(sigmoid) for Unit Continuous Distribution - <br/>\n",
    "This PR added sigmoid transform to Unit Continuous Distribution. To make the default transform compatible with PyMC4, I also added Sigmoid transform that used `tfb.Sigmoid` bijector.\n",
    "\n",
    "3. Pull Request [#212](https://github.com/pymc-devs/pymc4/pull/212) (Merged): Update design_guide notebook - <br/>\n",
    "This small PR fixed typos and variable names in `pymc4_design_guide.ipynb`.\n",
    "\n",
    "4. Issue [#211](https://github.com/pymc-devs/pymc4/issues/211) (Closed): Installation issues\n",
    "I encountered installation issues while setting up the working environment using pip. So, I created the issue and Luciano Paz helped me out with other ways of installing PyMC4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Projects\n",
    "1. Send to S3 - [Github](https://github.com/Sayam753/SendToS3) <br/>\n",
    "This python project sends backup files to AWS S3 bucket using Boto3. Searching for files is done by regex and results of logs are sent to email using smtplib.\n",
    "\n",
    "2. Osint-Spy - [Github](https://github.com/Sayam753/OSINT-SPY) <br/>\n",
    "This Python project performs Osint scan on email, domain, ip, organization, etc.\n",
    "This information can be used by Data Miners or Penetration Testers in order to find deep information about their target.\n",
    "\n",
    "3. Turbofan Degradation - [Colab](https://colab.research.google.com/drive/1sCZcJSmRarYbQKDYeaqiLnzXyzFolRC0) <br/>\n",
    "Implemented a Deep learning based Encoder-Decoder model ([paper](https://www.researchgate.net/publication/336150924_A_Novel_Deep_Learning-Based_Encoder-Decoder_Model_for_Remaining_Useful_Life_Prediction)) for analysing the turbofan degradation dataset provided by NASA.\n",
    "\n",
    "4. Neural Network from Scratch - [Colab](https://colab.research.google.com/drive/1iU38tTeEvUI_sjt6vVAuhedMWOPUdr5E) <br/>\n",
    "Implemented a deep neural network from scratch in numpy with custom hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic/Contact Information\n",
    "\n",
    " - Time Zone: UTC+05:30\n",
    " - Github Handle: [Sayam753](https://github.com/Sayam753)\n",
    " - Resume: [Google drive link](https://drive.google.com/file/d/1mrNC3qtieWKH1i2mhqH6xiFCt-EwGJ0b/view?usp=sharing), [Github link](https://github.com/Sayam753/Resume)\n",
    " - Contact details: [Gmail](sayamkumar049@gmail.com), [Yahoo](sayamkumar753@yahoo.in), [LinkedIn](https://www.linkedin.com/in/sayam049/), [Twitter](https://twitter.com/sayamkumar753), +91 9815247310 (Mobile)\n",
    "\n",
    "### Personal Info\n",
    "I am Sayam Kumar from Indian Institute of Information Technology Sri City, India. I am a second year Undergraduate pursuing a Bachelor's in Computer Science Engineering. I mostly code in Python. I am interested to work on the project to expand my knowledge in Machine Learning and Bayesian Statistics. With my continuous efforts to learn and know more about Bayesian Statistics, I believe I will be able to complete the project. Also this is my first time participating in GSoC. \n",
    "\n",
    "### Commitments\n",
    "As I have no other projects/internships planned for summers, I can spend 40~50 hours per week or more if required working on the project. Along the way, I will design progress reports and extensive documentation of the implementation of various classes. This will help in submitting reports to mentor and Google at evaluation time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Useful Papers\n",
    " - [Automatic Differentiation Variational Inference](https://arxiv.org/pdf/1603.00788.pdf). Kucukelbir, A., Tran, D., Ranganath, R., Gelman, A., and Blei, D. M. (2016).\n",
    " - [Automatic Variational Inference in Stan](https://arxiv.org/abs/1506.03431). Kucukelbir, A., Ranganath, R., Gelman, A., & Blei, D. (2015).\n",
    " - [Operator Variational Inference](https://arxiv.org/abs/1610.09033). Rajesh Ranganath, Jaan Altosaar, Dustin Tran, David M. Blei (2016).\n",
    " - [Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114). Kingma, D. P., & Welling, M. (2014)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
